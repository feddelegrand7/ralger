---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%"
)
```
# ralger <a><img src='man/figures/hex.png' align="right" height="200" /></a>



<!-- badges: start -->
[![CRAN status](https://www.r-pkg.org/badges/version/ralger)](https://cran.r-project.org/package=ralger)

<!-- badges: end -->


```{r echo=FALSE, message=FALSE, warning=FALSE, results="hide"}
library("badger")
```

```{r echo=FALSE, message=FALSE, warning=FALSE, results='asis'}
cat(badge_cran_download("ralger", "grand-total", "blue"))
```

The goal of **ralger** is to facilitate web scraping in R. 

## Installation

You can install the ralger package from [CRAN](https://cran.r-project.org/) with:

```{r eval=FALSE}
install.packages("ralger")

```

or you can install the development version from [GitHub](https://github.com/) with:

``` r
# install.packages("devtools")
devtools::install_github("feddelegrand7/ralger")
```
## scrap()

This is an example which shows how to extract firms denomination from the website of the [Algerian Chamber of Commerce and Industry](http://elmouchir.caci.dz) (CACI). For simplicity, we'll focus on firms operating within the capital (Algiers). 

```{r example}
library(ralger)

my_link <- "http://elmouchir.caci.dz/search_results.php?keyword=&category=&location=Alger&submit=Trouver"

my_node <- ".listing_default" # The CSS element, we recommend SelectorGadget

scrap(my_link, my_node)


```

If you want to scrap multiple list pages, just use `scrap()` in conjunction with `paste()`. Suppose, we want to extract the above information from the first 3 pages (starts from 0): 

```{r example2}
my_link <- "http://elmouchir.caci.dz/search_results.php?keyword=&category=&location=Alger&submit=Trouver&page=" 

my_node <- ".listing_default"

scrap(paste(my_link, 0:2), my_node)

```


## tidy_scrap()

If you want to extract a dataframe from a web page, you can use the `tidy_scrap()` function which returns a tidy dataframe according to the arguments that you introduce. The function takes four arguments:

- **link** : the link of the website you're interested for
- **nodes**: a vector of CSS elements that you want to extract. These elements will form the columns of your dataframe
- **colnames**: this argument represents the vector of names you want to assign to your columns. Note that you should respect the same order as within the **nodes** vector
- **clean**: if true the function will clean the tibble's columns. 

### Example

We'll work on the famous [IMDb website](https://www.imdb.com/). Let's say we need a dataframe composed of:

- The title of the 50 best ranked movies of all time
- Their release year
- Their rating

We will need to use the `tidy_scrap()` function as follows: 

```{r example3}

my_link <- "https://www.imdb.com/search/title/?groups=top_250&sort=user_rating"

my_nodes <- c(
  ".lister-item-header a", # The title 
  ".text-muted.unbold", # The year of release 
  ".ratings-imdb-rating strong" # The rating)
  )

names <- c("title", "year", "rating") # respect the nodes order


tidy_scrap(my_link, my_nodes, colnames = names)


```
Note that all columns will be of *character* class. you'll have to convert them according to your needs. Finally, I appreciate any feedback, please reach out or DM at [ihaddaden_moh_fodil](https://twitter.com/moh_fodil). 

