% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/weblink_scrap.R
\name{weblink_scrap}
\alias{weblink_scrap}
\title{Website web links scraping}
\usage{
weblink_scrap(link, contain = NULL, case_sensitive = FALSE, askRobot = FALSE)
}
\arguments{
\item{link}{the link of the web page to scrape}

\item{contain}{filter the web links according to the character string provided.}

\item{case_sensitive}{logical. Should the contain argument be case sensitive ? defaults to FALSE}

\item{askRobot}{logical. Should the function ask the robots.txt if we're allowed or not to scrape the web page ? Default is FALSE.}
}
\value{
a character vector.
}
\description{
This function is used to scrape web links from a website.
}
\examples{
\donttest{
# Extracting the web links within the World Bank research and publications page

link <- "https://www.worldbank.org/en/research"

weblink_scrap(link)
}

}
